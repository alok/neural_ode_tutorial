{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqFlux,OrdinaryDiffEq,Flux,Optim,Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = Float32[2.0;0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan=(0.0f0,1.5f0)\n",
    "tsteps=range(tspan...,length=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function true_ode(du,u,p,t)\n",
    "    true_a = [-0.1 2.0; -2.0 -0.1]\n",
    "    du .= ((u.^3)'true_a)'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true_ode=ODEProblem(true_ode,u0,tspan) # solve ode with starting condition over these points\n",
    "ode_data=Array(solve(prob_true_ode,Tsit5(),saveat=tsteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dudt2 = FastChain(\n",
    "    (x,p)-> x.^3,\n",
    "    FastDense(2,50,tanh),\n",
    "    FastDense(50,2)\n",
    ")\n",
    "prob_neural_ode=NeuralODE(dudt2,tspan,Tsit5(),saveat=tsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_neural_ode(p)\n",
    "    Array(prob_neural_ode(u0,p))\n",
    "end\n",
    "\n",
    "function loss_neural_ode(p)\n",
    "    pred= predict_neural_ode(p)\n",
    "    loss=sum(abs2,ode_data.-pred)\n",
    "    return loss,pred\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function callback(p,l,pred;doplot=false)::Bool\n",
    "    display(l)\n",
    "    #plot pred vs data\n",
    "    plt=scatter(tsteps,ode_data[1,:],label=\"data\")\n",
    "    scatter!(plt,tsteps,pred[1,:],label=\"prediction\")\n",
    "    \n",
    "    if doplot\n",
    "        display(plot(plt))\n",
    "    end\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode = DiffEqFlux.sciml_train(loss_neural_ode, prob_neural_ode.p,\n",
    "                                          ADAM(0.05), cb = callback,\n",
    "                                          maxiters = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neuralode2 = DiffEqFlux.sciml_train(loss_neural_ode,\n",
    "                                           result_neuralode.minimizer,\n",
    "                                           LBFGS(),\n",
    "                                           cb = callback,\n",
    "                                           allow_f_increases = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqFlux, OrdinaryDiffEq, Flux, NNlib, MLDataUtils, Printf\n",
    "using Flux: logitcrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using MLDatasets\n",
    "using CUDA\n",
    "CUDA.allowscalar(false)\n",
    "\n",
    "function loadmnist(batchsize = bs, train_split = 0.9)\n",
    "    # Use MLDataUtils LabelEnc for natural onehot conversion\n",
    "    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n",
    "                                      LabelEnc.NativeLabels(collect(0:9)))\n",
    "    # Load MNIST\n",
    "    imgs, labels_raw = MNIST.traindata();\n",
    "    # Process images into (H,W,C,BS) batches\n",
    "    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n",
    "    y_data = onehot(labels_raw)\n",
    "    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n",
    "                                                         p = train_split)\n",
    "    return (\n",
    "        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n",
    "                   shuffle = true),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n",
    "                   shuffle = false)\n",
    "    )\n",
    "end\n",
    "# Main\n",
    "const bs = 128\n",
    "const train_split = 0.9\n",
    "train_dataloader, test_dataloader = loadmnist(bs, train_split)\n",
    "\n",
    "down = Chain(flatten, Dense(784, 20, tanh)) |> gpu\n",
    "\n",
    "nn = Chain(Dense(20, 10, tanh),\n",
    "           Dense(10, 10, tanh),\n",
    "           Dense(10, 20, tanh)) |> gpu\n",
    "\n",
    "\n",
    "nn_ode = NeuralODE(nn, (0.f0, 1.f0), Tsit5(),\n",
    "                   save_everystep = false,\n",
    "                   reltol = 1e-3, abstol = 1e-3,\n",
    "                   save_start = false) |> gpu\n",
    "\n",
    "fc  = Chain(Dense(20, 10)) |> gpu\n",
    "\n",
    "function DiffEqArray_to_Array(x)\n",
    "    xarr = gpu(x)\n",
    "    return reshape(xarr, size(xarr)[1:2])\n",
    "end\n",
    "\n",
    "# Build our over-all model topology\n",
    "model = Chain(down,\n",
    "              nn_ode,\n",
    "              DiffEqArray_to_Array,\n",
    "              fc) |> gpu;\n",
    "\n",
    "# To understand the intermediate NN-ODE layer, we can examine it's dimensionality\n",
    "img, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1]\n",
    "\n",
    "x_d = down(img)\n",
    "\n",
    "# We can see that we can compute the forward pass through the NN topology\n",
    "# featuring an NNODE layer.\n",
    "x_m = model(img)\n",
    "\n",
    "classify(x) = argmax.(eachcol(x))\n",
    "\n",
    "function accuracy(model, data; n_batches = 100)\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for (i, (x, y)) in enumerate(collect(data))\n",
    "        # Only evaluate accuracy for n_batches\n",
    "        i > n_batches && break\n",
    "        target_class = classify(cpu(y))\n",
    "        predicted_class = classify(cpu(model(x)))\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end\n",
    "\n",
    "# burn in accuracy\n",
    "accuracy(model, train_dataloader)\n",
    "\n",
    "loss(x, y) = logitcrossentropy(model(x), y)\n",
    "\n",
    "# burn in loss\n",
    "loss(img, lab)\n",
    "\n",
    "opt = ADAM(0.05)\n",
    "iter = 0\n",
    "\n",
    "cb() = begin\n",
    "    global iter += 1\n",
    "    # Monitor that the weights do infact update\n",
    "    # Every 10 training iterations show accuracy\n",
    "    if iter % 10 == 1\n",
    "        train_accuracy = accuracy(model, train_dataloader) * 100\n",
    "        test_accuracy = accuracy(model, test_dataloader;\n",
    "                                 n_batches = length(test_dataloader)) * 100\n",
    "        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n",
    "                iter, train_accuracy, test_accuracy)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Train the NN-ODE and monitor the loss and weights.\n",
    "Flux.train!(loss, params(down, nn_ode.p, fc), train_dataloader, opt, cb = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
